{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovpZyIhNIgoq"
   },
   "source": [
    "# Machado de Assis Bot\n",
    "**Portuguese Text Generation with Artificial Neural Networks**\n",
    "<img src = \"MachadoAssisBot.png\">\n",
    "\n",
    "- Project developed by Marcelo Rovai, based on lessons learned with the great teacher [José Portilla](https://www.udemy.com/course/complete-tensorflow-2-and-keras-deep-learning-bootcamp/#instructor-1) during his fantastic course: [Complete Tensorflow 2 and Keras Deep Learning Bootcamp](https://www.udemy.com/course/complete-tensorflow-2-and-keras-deep-learning-bootcamp/#instructor-1)\n",
    "- The Artificial network developed on this project, generates text, character by character. Please see this following site, for a great general visual explanation: [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and also check the [TF site for details](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00mwlQwloO5_"
   },
   "outputs": [],
   "source": [
    "# Should be run when GOOGLE COLLAB is used\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T14:41:37.063066Z",
     "start_time": "2020-06-27T14:41:22.977990Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WBd69MDEm4rF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T14:41:40.715560Z",
     "start_time": "2020-06-27T14:41:40.710320Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kycWuRI9oaSP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "apj1Chkdm4rS"
   },
   "source": [
    "## Step 1: The Data\n",
    "\n",
    "Machado de Assis original XIX century books can be downloaded from: [Gutenberg Project](https://www.gutenberg.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:18:26.582407Z",
     "start_time": "2020-06-27T15:18:26.425284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casmurro.txt    mao_luva.txt    memorias.txt    quincas.txt\n",
      "esau_jacob.txt  memorial.txt    papeis.txt\n"
     ]
    }
   ],
   "source": [
    "ls machado/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:23:25.070126Z",
     "start_time": "2020-06-27T15:23:25.067595Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "path = './machado/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:49:31.671246Z",
     "start_time": "2020-06-27T15:49:31.646104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2418451"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = open(path+'casmurro.txt', 'r').read()\n",
    "text2 = open(path+'mao_luva.txt', 'r').read()\n",
    "text3 = open(path+'memorias.txt', 'r').read()\n",
    "text4 = open(path+'quincas.txt', 'r').read()\n",
    "text5 = open(path+'esau_jacob.txt', 'r').read()\n",
    "text6 = open(path+'memorial.txt', 'r').read()\n",
    "text7 = open(path+'papeis.txt', 'r').read()\n",
    "text = text1+text2+text3+text4+text5+text6+text7\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:49:50.112756Z",
     "start_time": "2020-06-27T15:49:50.109576Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Duhg9NrUymwO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOM CASMURRO\n",
      "\n",
      "I\n",
      "\n",
      "Do titulo.\n",
      "\n",
      "Uma noite destas, vindo da cidade para o Engenho Novo, encontrei no\n",
      "trem da Central um rapaz aqui do bairro, que eu conheço de vista e\n",
      "de chapéo. Comprimentou-me, sentou-se ao pé de mim, falou da lua e\n",
      "dos ministros, e acabou recitando-me versos. A viagem era curta, e os\n",
      "versos póde ser que não fossem inteiramente maus. Succedeu, porém, que\n",
      "como eu estava cançado, fechei os olhos tres ou quatro vezes; tanto\n",
      "bastou para que elle interrompesse a leitura e mettesse os v\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:33:50.241245Z",
     "start_time": "2020-06-27T15:33:50.237448Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Duhg9NrUymwO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s principaes medicos\n",
      "da côrte; foi necessario recorrer á simulação, e dal-os, emfim, como\n",
      "receitados por um ignorantão do tempo. Mas era tarde. A morte levou-o,\n",
      "ao cabo de duas semanas.\n",
      "\n",
      "--Joaquim Soares? bradou attonito o cunhado, ao saber da verba\n",
      "testamentaria do defunto, ordenando que o caixão fosse fabricado por\n",
      "aquelle industrial. Mas os caixões d'esse sujeito não prestam para\n",
      "nada, e...\n",
      "\n",
      "--Paciencia! interrompeu a mulher; a vontade do mano ha de comprir-se.\n",
      "\n",
      "\n",
      "FIM DA VERBA TESTAMENTARIA\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[-500:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and saving a single file (corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:58:41.460950Z",
     "start_time": "2020-06-27T15:58:41.457860Z"
    }
   },
   "outputs": [],
   "source": [
    "machado = open('machado.txt','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:59:04.558555Z",
     "start_time": "2020-06-27T15:59:04.550147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2418451"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machado.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:59:34.515114Z",
     "start_time": "2020-06-27T15:59:34.512582Z"
    }
   },
   "outputs": [],
   "source": [
    "machado.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXUmR627m4rd"
   },
   "source": [
    "### Understanding unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T17:44:30.846218Z",
     "start_time": "2020-06-27T17:44:30.834652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2418451"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open('machado.txt', 'r').read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:35:02.172306Z",
     "start_time": "2020-06-27T15:35:02.134245Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '$', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '§', '«', '°', '»', 'À', 'Á', 'Ã', 'Ç', 'É', 'Ê', 'Í', 'Ó', 'Ú', 'à', 'á', 'â', 'ã', 'æ', 'ç', 'è', 'é', 'ê', 'í', 'î', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ú', 'û', 'œ', '—', '’']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(vocab)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## Step 2: Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "### Text Vectorization\n",
    "\n",
    "We know a neural network can't take in the raw string data, we need to assign numbers to each character. Let's create two dictionaries that can go from numeric index to character and character to numeric index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:35:12.188204Z",
     "start_time": "2020-06-27T15:35:12.185259Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "char_to_ind = {char:ind for ind, char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:35:13.085947Z",
     "start_time": "2020-06-27T15:35:13.078738Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fmmP5iCwm4rp",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '$': 4,\n",
       " '&': 5,\n",
       " \"'\": 6,\n",
       " '(': 7,\n",
       " ')': 8,\n",
       " '*': 9,\n",
       " '+': 10,\n",
       " ',': 11,\n",
       " '-': 12,\n",
       " '.': 13,\n",
       " '0': 14,\n",
       " '1': 15,\n",
       " '2': 16,\n",
       " '3': 17,\n",
       " '4': 18,\n",
       " '5': 19,\n",
       " '6': 20,\n",
       " '7': 21,\n",
       " '8': 22,\n",
       " '9': 23,\n",
       " ':': 24,\n",
       " ';': 25,\n",
       " '=': 26,\n",
       " '?': 27,\n",
       " 'A': 28,\n",
       " 'B': 29,\n",
       " 'C': 30,\n",
       " 'D': 31,\n",
       " 'E': 32,\n",
       " 'F': 33,\n",
       " 'G': 34,\n",
       " 'H': 35,\n",
       " 'I': 36,\n",
       " 'J': 37,\n",
       " 'K': 38,\n",
       " 'L': 39,\n",
       " 'M': 40,\n",
       " 'N': 41,\n",
       " 'O': 42,\n",
       " 'P': 43,\n",
       " 'Q': 44,\n",
       " 'R': 45,\n",
       " 'S': 46,\n",
       " 'T': 47,\n",
       " 'U': 48,\n",
       " 'V': 49,\n",
       " 'W': 50,\n",
       " 'X': 51,\n",
       " 'Y': 52,\n",
       " 'Z': 53,\n",
       " '[': 54,\n",
       " ']': 55,\n",
       " '_': 56,\n",
       " 'a': 57,\n",
       " 'b': 58,\n",
       " 'c': 59,\n",
       " 'd': 60,\n",
       " 'e': 61,\n",
       " 'f': 62,\n",
       " 'g': 63,\n",
       " 'h': 64,\n",
       " 'i': 65,\n",
       " 'j': 66,\n",
       " 'k': 67,\n",
       " 'l': 68,\n",
       " 'm': 69,\n",
       " 'n': 70,\n",
       " 'o': 71,\n",
       " 'p': 72,\n",
       " 'q': 73,\n",
       " 'r': 74,\n",
       " 's': 75,\n",
       " 't': 76,\n",
       " 'u': 77,\n",
       " 'v': 78,\n",
       " 'w': 79,\n",
       " 'x': 80,\n",
       " 'y': 81,\n",
       " 'z': 82,\n",
       " '§': 83,\n",
       " '«': 84,\n",
       " '°': 85,\n",
       " '»': 86,\n",
       " 'À': 87,\n",
       " 'Á': 88,\n",
       " 'Ã': 89,\n",
       " 'Ç': 90,\n",
       " 'É': 91,\n",
       " 'Ê': 92,\n",
       " 'Í': 93,\n",
       " 'Ó': 94,\n",
       " 'Ú': 95,\n",
       " 'à': 96,\n",
       " 'á': 97,\n",
       " 'â': 98,\n",
       " 'ã': 99,\n",
       " 'æ': 100,\n",
       " 'ç': 101,\n",
       " 'è': 102,\n",
       " 'é': 103,\n",
       " 'ê': 104,\n",
       " 'í': 105,\n",
       " 'î': 106,\n",
       " 'ñ': 107,\n",
       " 'ò': 108,\n",
       " 'ó': 109,\n",
       " 'ô': 110,\n",
       " 'õ': 111,\n",
       " 'ú': 112,\n",
       " 'û': 113,\n",
       " 'œ': 114,\n",
       " '—': 115,\n",
       " '’': 116}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:35:31.266397Z",
     "start_time": "2020-06-27T15:35:31.262902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:35:36.444068Z",
     "start_time": "2020-06-27T15:35:36.440912Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "30ZYaWAOm4rt"
   },
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:35:37.512138Z",
     "start_time": "2020-06-27T15:35:37.507898Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_6JPOWwJm4rz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', ' ', '!', '\"', '$', '&', \"'\", '(', ')', '*', '+', ',', '-',\n",
       "       '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';',\n",
       "       '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
       "       'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
       "       'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h',\n",
       "       'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
       "       'v', 'w', 'x', 'y', 'z', '§', '«', '°', '»', 'À', 'Á', 'Ã', 'Ç',\n",
       "       'É', 'Ê', 'Í', 'Ó', 'Ú', 'à', 'á', 'â', 'ã', 'æ', 'ç', 'è', 'é',\n",
       "       'ê', 'í', 'î', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ú', 'û', 'œ', '—', '’'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:35:46.075010Z",
     "start_time": "2020-06-27T15:35:46.070660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:35:47.442844Z",
     "start_time": "2020-06-27T15:35:47.149247Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3fhOqV0lm4r2"
   },
   "outputs": [],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:35:48.401789Z",
     "start_time": "2020-06-27T15:35:48.397644Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "axOX7rFom4r5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31, 42, 40, ...,  0,  0,  0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:35:49.325874Z",
     "start_time": "2020-06-27T15:35:49.321520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2418451,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZfqhkYCymwX"
   },
   "source": [
    "We now have a mapping we can use to go back and forth from characters to numerics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:36:03.931806Z",
     "start_time": "2020-06-27T15:36:03.927770Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tFs1Uza-m4r9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DOM CASMURRO\\n\\nI\\n\\nDo titulo.\\n\\nUma noite destas, vindo da cidade para o Engenho Novo, encontrei no\\ntrem da Central um rapaz aqui do bairro, que eu conheço de vista e\\nde chapéo. Comprimentou-me, sentou-se ao pé de mim, falou da lua e\\ndos ministros, e acabou recitando-me versos. A viagem era curta, e os\\nversos póde ser que não fossem inteiramente maus. Succedeu, porém, que\\ncomo eu estava cançado, fechei os olhos tres ou quatro vezes; tanto\\nbastou para que elle interrompesse a leitura e mettesse os v'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = text[:500]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:36:05.255842Z",
     "start_time": "2020-06-27T15:36:05.250484Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gIqUCK5Am4sB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31,  42,  40,   1,  30,  28,  46,  40,  48,  45,  45,  42,   0,\n",
       "         0,  36,   0,   0,  31,  71,   1,  76,  65,  76,  77,  68,  71,\n",
       "        13,   0,   0,  48,  69,  57,   1,  70,  71,  65,  76,  61,   1,\n",
       "        60,  61,  75,  76,  57,  75,  11,   1,  78,  65,  70,  60,  71,\n",
       "         1,  60,  57,   1,  59,  65,  60,  57,  60,  61,   1,  72,  57,\n",
       "        74,  57,   1,  71,   1,  32,  70,  63,  61,  70,  64,  71,   1,\n",
       "        41,  71,  78,  71,  11,   1,  61,  70,  59,  71,  70,  76,  74,\n",
       "        61,  65,   1,  70,  71,   0,  76,  74,  61,  69,   1,  60,  57,\n",
       "         1,  30,  61,  70,  76,  74,  57,  68,   1,  77,  69,   1,  74,\n",
       "        57,  72,  57,  82,   1,  57,  73,  77,  65,   1,  60,  71,   1,\n",
       "        58,  57,  65,  74,  74,  71,  11,   1,  73,  77,  61,   1,  61,\n",
       "        77,   1,  59,  71,  70,  64,  61, 101,  71,   1,  60,  61,   1,\n",
       "        78,  65,  75,  76,  57,   1,  61,   0,  60,  61,   1,  59,  64,\n",
       "        57,  72, 103,  71,  13,   1,  30,  71,  69,  72,  74,  65,  69,\n",
       "        61,  70,  76,  71,  77,  12,  69,  61,  11,   1,  75,  61,  70,\n",
       "        76,  71,  77,  12,  75,  61,   1,  57,  71,   1,  72, 103,   1,\n",
       "        60,  61,   1,  69,  65,  69,  11,   1,  62,  57,  68,  71,  77,\n",
       "         1,  60,  57,   1,  68,  77,  57,   1,  61,   0,  60,  71,  75,\n",
       "         1,  69,  65,  70,  65,  75,  76,  74,  71,  75,  11,   1,  61,\n",
       "         1,  57,  59,  57,  58,  71,  77,   1,  74,  61,  59,  65,  76,\n",
       "        57,  70,  60,  71,  12,  69,  61,   1,  78,  61,  74,  75,  71,\n",
       "        75,  13,   1,  28,   1,  78,  65,  57,  63,  61,  69,   1,  61,\n",
       "        74,  57,   1,  59,  77,  74,  76,  57,  11,   1,  61,   1,  71,\n",
       "        75,   0,  78,  61,  74,  75,  71,  75,   1,  72, 109,  60,  61,\n",
       "         1,  75,  61,  74,   1,  73,  77,  61,   1,  70,  99,  71,   1,\n",
       "        62,  71,  75,  75,  61,  69,   1,  65,  70,  76,  61,  65,  74,\n",
       "        57,  69,  61,  70,  76,  61,   1,  69,  57,  77,  75,  13,   1,\n",
       "        46,  77,  59,  59,  61,  60,  61,  77,  11,   1,  72,  71,  74,\n",
       "       103,  69,  11,   1,  73,  77,  61,   0,  59,  71,  69,  71,   1,\n",
       "        61,  77,   1,  61,  75,  76,  57,  78,  57,   1,  59,  57,  70,\n",
       "       101,  57,  60,  71,  11,   1,  62,  61,  59,  64,  61,  65,   1,\n",
       "        71,  75,   1,  71,  68,  64,  71,  75,   1,  76,  74,  61,  75,\n",
       "         1,  71,  77,   1,  73,  77,  57,  76,  74,  71,   1,  78,  61,\n",
       "        82,  61,  75,  25,   1,  76,  57,  70,  76,  71,   0,  58,  57,\n",
       "        75,  76,  71,  77,   1,  72,  57,  74,  57,   1,  73,  77,  61,\n",
       "         1,  61,  68,  68,  61,   1,  65,  70,  76,  61,  74,  74,  71,\n",
       "        69,  72,  61,  75,  75,  61,   1,  57,   1,  68,  61,  65,  76,\n",
       "        77,  74,  57,   1,  61,   1,  69,  61,  76,  76,  61,  75,  75,\n",
       "        61,   1,  71,  75,   1,  78])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbmsf23Bymwe"
   },
   "source": [
    "## Step 3: Creating Batches\n",
    "\n",
    "Overall what we are trying to achieve is to have the model predict the next highest probability character given a historical sequence of characters. Its up to us (the user) to choose how long that historic sequence. Too short a sequence and we don't have enough information (e.g. given the letter \"a\" , what is the next character) , too long a sequence and training will take too long and most likely overfit to sequence characters that are irrelevant to characters farther out. While there is no correct sequence length choice, you should consider the text itself, how long normal phrases are in it, and a reasonable idea of what characters/words are relevant to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:36:13.847694Z",
     "start_time": "2020-06-27T15:36:13.844668Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pAvUYFk7m4sF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOM CASMURRO\n",
      "\n",
      "I\n",
      "\n",
      "Do titulo.\n",
      "\n",
      "Uma noite destas, vindo da cidade para o Engenho Novo, encontrei no\n",
      "trem da Central um rapaz aqui do bairro, que eu conheço de vista e\n",
      "de chapéo. Comprimentou-me, sentou-se ao pé de mim, falou da lua e\n",
      "dos ministros, e acabou recitando-me versos. A viagem era curta, e os\n",
      "versos póde ser que não fossem inteiramente maus. Succedeu, porém, que\n",
      "como eu estava cançado, fechei os olhos tres ou quatro vezes; tanto\n",
      "bastou para que elle interrompesse a leitura e mettesse os v\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:36:52.416716Z",
     "start_time": "2020-06-27T15:36:52.414268Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "D45OYgOfm4sJ"
   },
   "outputs": [],
   "source": [
    "line = \"Uma noite destas, vindo da cidade para o Engenho Novo, encontrei no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:36:53.427934Z",
     "start_time": "2020-06-27T15:36:53.423374Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7dKiEVN8m4sL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:37:47.746532Z",
     "start_time": "2020-06-27T15:37:47.743626Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "olX67f6-m4sP"
   },
   "outputs": [],
   "source": [
    "par = \"\"\"Uma noite destas, vindo da cidade para o Engenho Novo, encontrei no\n",
    "trem da Central um rapaz aqui do bairro, que eu conheço de vista e\n",
    "de chapéo.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:37:48.351269Z",
     "start_time": "2020-06-27T15:37:48.347435Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qal7MQnqm4sQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 120 as a general paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Training Sequences\n",
    "\n",
    "The actual text data will be the text sequence shifted one character forward. For example:\n",
    "\n",
    "Sequence In: \"Hello my nam\"\n",
    "Sequence Out: \"ello my name\"\n",
    "\n",
    "\n",
    "We can use the `tf.data.Dataset.from_tensor_slices` function to convert a text vector into a stream of character indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:38:23.369434Z",
     "start_time": "2020-06-27T15:38:23.367263Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0UHJDA39zf-O"
   },
   "outputs": [],
   "source": [
    "seq_len = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:38:26.251822Z",
     "start_time": "2020-06-27T15:38:26.248730Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7VRSK4cOm4sZ"
   },
   "outputs": [],
   "source": [
    "total_num_seq = len(text)//(seq_len+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:38:26.903629Z",
     "start_time": "2020-06-27T15:38:26.899981Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xtW0jbbvm4sc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19987"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:38:33.076279Z",
     "start_time": "2020-06-27T15:38:33.032538Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ciatnowvm4se"
   },
   "outputs": [],
   "source": [
    "# Create Training Sequences\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:38:33.801097Z",
     "start_time": "2020-06-27T15:38:33.797641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:38:55.515940Z",
     "start_time": "2020-06-27T15:38:55.513736Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ciatnowvm4se",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in char_dataset.take(500):\n",
    "#      print(ind_to_char[i.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZSYAcQV8OGP"
   },
   "source": [
    "The **batch** method converts these individual character calls into sequences we can feed in as a batch. We use seq_len+1 because of zero indexing. Here is what drop_remainder means:\n",
    "\n",
    "drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
    "    whether the last batch should be dropped in the case it has fewer than\n",
    "    `batch_size` elements; the default behavior is not to drop the smaller\n",
    "    batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:38:59.826076Z",
     "start_time": "2020-06-27T15:38:59.822417Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "l4hkDU3i7ozi"
   },
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:39:01.555186Z",
     "start_time": "2020-06-27T15:39:01.551381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (121,), types: tf.int64>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbLcIPBj_mWZ"
   },
   "source": [
    "Now that we have our sequences, we will perform the following steps for each one to create our target text sequences:\n",
    "\n",
    "1. Grab the input text sequence\n",
    "2. Assign the target text sequence as the input text sequence shifted by one step forward\n",
    "3. Group them together as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:39:09.077414Z",
     "start_time": "2020-06-27T15:39:09.073960Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def create_seq_targets(seq): # Hello my name\n",
    "    input_txt = seq[:-1]     # Hello my nam\n",
    "    target_txt = seq[1:]     # ello my name\n",
    "    return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:39:10.802129Z",
     "start_time": "2020-06-27T15:39:10.719851Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "HszljTg8m4so"
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T13:44:59.166950Z",
     "start_time": "2020-06-27T13:44:59.164761Z"
    }
   },
   "outputs": [],
   "source": [
    "# for test only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:39:16.588178Z",
     "start_time": "2020-06-27T15:39:16.564975Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JkPa7AMrm4sq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31 42 40  1 30 28 46 40 48 45 45 42  0  0 36  0  0 31 71  1 76 65 76 77\n",
      " 68 71 13  0  0 48 69 57  1 70 71 65 76 61  1 60 61 75 76 57 75 11  1 78\n",
      " 65 70 60 71  1 60 57  1 59 65 60 57 60 61  1 72 57 74 57  1 71  1 32 70\n",
      " 63 61 70 64 71  1 41 71 78 71 11  1 61 70 59 71 70 76 74 61 65  1 70 71\n",
      "  0 76 74 61 69  1 60 57  1 30 61 70 76 74 57 68  1 77 69  1 74 57 72 57]\n",
      "DOM CASMURRO\n",
      "\n",
      "I\n",
      "\n",
      "Do titulo.\n",
      "\n",
      "Uma noite destas, vindo da cidade para o Engenho Novo, encontrei no\n",
      "trem da Central um rapa\n",
      "\n",
      "\n",
      "[42 40  1 30 28 46 40 48 45 45 42  0  0 36  0  0 31 71  1 76 65 76 77 68\n",
      " 71 13  0  0 48 69 57  1 70 71 65 76 61  1 60 61 75 76 57 75 11  1 78 65\n",
      " 70 60 71  1 60 57  1 59 65 60 57 60 61  1 72 57 74 57  1 71  1 32 70 63\n",
      " 61 70 64 71  1 41 71 78 71 11  1 61 70 59 71 70 76 74 61 65  1 70 71  0\n",
      " 76 74 61 69  1 60 57  1 30 61 70 76 74 57 68  1 77 69  1 74 57 72 57 82]\n",
      "OM CASMURRO\n",
      "\n",
      "I\n",
      "\n",
      "Do titulo.\n",
      "\n",
      "Uma noite destas, vindo da cidade para o Engenho Novo, encontrei no\n",
      "trem da Central um rapaz\n",
      "[  1  57  73  77  65   1  60  71   1  58  57  65  74  74  71  11   1  73\n",
      "  77  61   1  61  77   1  59  71  70  64  61 101  71   1  60  61   1  78\n",
      "  65  75  76  57   1  61   0  60  61   1  59  64  57  72 103  71  13   1\n",
      "  30  71  69  72  74  65  69  61  70  76  71  77  12  69  61  11   1  75\n",
      "  61  70  76  71  77  12  75  61   1  57  71   1  72 103   1  60  61   1\n",
      "  69  65  69  11   1  62  57  68  71  77   1  60  57   1  68  77  57   1\n",
      "  61   0  60  71  75   1  69  65  70  65  75  76]\n",
      " aqui do bairro, que eu conheço de vista e\n",
      "de chapéo. Comprimentou-me, sentou-se ao pé de mim, falou da lua e\n",
      "dos minist\n",
      "\n",
      "\n",
      "[ 57  73  77  65   1  60  71   1  58  57  65  74  74  71  11   1  73  77\n",
      "  61   1  61  77   1  59  71  70  64  61 101  71   1  60  61   1  78  65\n",
      "  75  76  57   1  61   0  60  61   1  59  64  57  72 103  71  13   1  30\n",
      "  71  69  72  74  65  69  61  70  76  71  77  12  69  61  11   1  75  61\n",
      "  70  76  71  77  12  75  61   1  57  71   1  72 103   1  60  61   1  69\n",
      "  65  69  11   1  62  57  68  71  77   1  60  57   1  68  77  57   1  61\n",
      "   0  60  71  75   1  69  65  70  65  75  76  74]\n",
      "aqui do bairro, que eu conheço de vista e\n",
      "de chapéo. Comprimentou-me, sentou-se ao pé de mim, falou da lua e\n",
      "dos ministr\n"
     ]
    }
   ],
   "source": [
    "for input_txt, target_txt in  dataset.take(2):\n",
    "    print(input_txt.numpy())\n",
    "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_txt.numpy())\n",
    "    # There is an extra whitespace!\n",
    "    print(''.join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### Generating training batches\n",
    "\n",
    "Now that we have the actual sequences, we will create the batches, we want to shuffle these sequences into a random order, so the model doesn't overfit to any section of the text, but can instead generate characters given any seed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:39:29.168866Z",
     "start_time": "2020-06-27T15:39:29.164819Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "p2pGotuNzf-S"
   },
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 128\n",
    "\n",
    "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:39:31.469716Z",
     "start_time": "2020-06-27T15:39:31.465954Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gmcCALymm4su"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## Step 4: Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    "We will use an LSTM based model with a few extra features, including an embedding layer to start off with and **two** LSTM layers. We based this model architecture off the [DeepMoji](https://deepmoji.mit.edu/) and the original source code can be found [here](https://github.com/bfelbo/DeepMoji).\n",
    "\n",
    "The embedding layer will serve as the input layer, which essentially creates a lookup table that maps the numbers indices of each character to a vector with \"embedding dim\" number of dimensions. As you can imagine, the larger this embedding size, the more complex the training. This is similar to the idea behind word2vec, where words are mapped to some n-dimensional space. Embedding before feeding straight into the LSTM usually leads to more realisitic results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:39:46.271091Z",
     "start_time": "2020-06-27T15:39:46.268374Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embed_dim = 64\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_neurons = 1026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Atb060h5m4s0"
   },
   "source": [
    "Now let's create a function that easily adapts to different variables as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcMbIy-xj-w-"
   },
   "source": [
    "### Setting up Loss Function\n",
    "\n",
    "For our loss we will use sparse categorical crossentropy, which we can import from Keras. We will also set this as logits=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5N4Qxbij5gY"
   },
   "source": [
    "https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:40:00.399526Z",
     "start_time": "2020-06-27T15:40:00.396595Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "FrOOK61Olm1C"
   },
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:40:02.545794Z",
     "start_time": "2020-06-27T15:40:02.541119Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n",
    "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "    # Final Dense Layer to Predict\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.compile(optimizer='adam', loss=sparse_cat_loss) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:40:04.373831Z",
     "start_time": "2020-06-27T15:40:04.136174Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "  vocab_size = vocab_size,\n",
    "  embed_dim=embed_dim,\n",
    "  rnn_neurons=rnn_neurons,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:40:05.221314Z",
     "start_time": "2020-06-27T15:40:05.216384Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "liXuTFYMm4s6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 64)           7488      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1026)         3361176   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 117)          120159    \n",
      "=================================================================\n",
      "Total params: 3,488,823\n",
      "Trainable params: 3,488,823\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Step 5: Training the model\n",
    "\n",
    "Let's make sure everything is ok with our model before we spend too much time training! Let's pass in a batch to confirm the model currently predicts random characters without any training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:40:23.696335Z",
     "start_time": "2020-06-27T15:40:21.096409Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "A4ygvfHn-wan"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 120, 117)  <=== (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "\n",
    "  # Predict off some random batch\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "\n",
    "  # Display the dimensions of the predictions\n",
    "  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T14:23:25.380654Z",
     "start_time": "2020-06-27T14:23:25.375869Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5ld8z3LPBAuv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 84), dtype=float32, numpy=\n",
       "array([[ 1.8190127e-04, -1.6419976e-03,  3.9721478e-04, ...,\n",
       "        -9.5687859e-04,  3.0489508e-03,  8.8712717e-05],\n",
       "       [ 1.1579794e-02, -5.5200760e-03,  7.0615485e-03, ...,\n",
       "         9.6486701e-04,  1.5863801e-03,  6.0194358e-04],\n",
       "       [ 4.2760507e-03, -1.9974667e-03,  8.0016572e-03, ...,\n",
       "         2.1912388e-03, -2.1127991e-03,  3.4331047e-04],\n",
       "       ...,\n",
       "       [ 7.5974653e-04, -5.6152726e-03,  5.9420167e-04, ...,\n",
       "         7.5961314e-03, -5.2516577e-03, -5.8296616e-03],\n",
       "       [ 1.4868858e-03, -3.1611430e-03, -4.7921604e-03, ...,\n",
       "         7.3029827e-03, -4.9130362e-03, -5.5329129e-04],\n",
       "       [ 8.2738942e-04, -3.1001735e-03, -1.8603078e-03, ...,\n",
       "         2.8914216e-03,  3.6097656e-04, -6.5167190e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:40:50.584848Z",
     "start_time": "2020-06-27T15:40:50.581082Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_achqjT-BGyY"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:40:51.625596Z",
     "start_time": "2020-06-27T15:40:51.623045Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xWrPFk2nBJX4"
   },
   "outputs": [],
   "source": [
    "#sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:40:52.144670Z",
     "start_time": "2020-06-27T15:40:52.141646Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Wi80PQVtBLqj"
   },
   "outputs": [],
   "source": [
    "# Reformat to not be a lists of lists\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:40:53.090984Z",
     "start_time": "2020-06-27T15:40:53.085518Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4qYkIg00-wjq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 88,   4,   1,  57, 104,  49,  36,  90, 111,  87,  89,  33,  74,\n",
       "         7,  39, 109,  82,   0,  70,  87,  22, 112,  26,  18,  93,   6,\n",
       "        79,   1,  41,  60,  51,  55,  12,  45,  10,  45,  50,  90,  75,\n",
       "        63,   8,  18,  56,  84,  70,  61,  36, 109, 106,  45,  24,  54,\n",
       "        52,  67,  61,  35,  24,  13, 100,  91, 104,  46,  74,  75,  39,\n",
       "        77,  49,  83,  34,  39,  10,  32,  88,  79, 105,  37,  41,  40,\n",
       "        93,  52,  99,  94,  37,  23,  75,  91,  23, 100,  48,  32,  53,\n",
       "        89,  18,  24, 113,  89,  46,  39,  27,  45,  21,  93,  42,  43,\n",
       "        14,  61,  60,  65, 114,  95,  37,  91,  84,  14,  54,  57,  77,\n",
       "         8,  63,  64])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:40:55.620463Z",
     "start_time": "2020-06-27T15:40:55.616375Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "H9-P_XqQ_7wY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the input seq: \n",
      "\n",
      ", temperando o mal com\n",
      "a opinião anti-russa, dava á podridão das suas carnes um reflexo\n",
      "espiritual que as consolava. Ha \n",
      "\n",
      "\n",
      "Next Char Predictions: \n",
      "\n",
      "Á$ aêVIÇõÀÃFr(Lóz\n",
      "nÀ8ú=4Í'w NdX]-R+RWÇsg)4_«neIóîR:[YkeH:.æÉêSrsLuV§GL+EÁwíJNMÍYãÓJ9sÉ9æUEZÃ4:ûÃSL?R7ÍOP0ediœÚJÉ«0[au)gh\n"
     ]
    }
   ],
   "source": [
    "print(\"Given the input seq: \\n\")\n",
    "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
    "print('\\n')\n",
    "print(\"Next Char Predictions: \\n\")\n",
    "print(\"\".join(ind_to_char[sampled_indices ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAOE4rzuBh7f"
   },
   "source": [
    "After confirming the dimensions are working, let's train our network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:41:06.279729Z",
     "start_time": "2020-06-27T15:41:06.277063Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZYDQjKTlm4s8"
   },
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model should be trained using GPU on Google Collabs. It is faster than a CPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:41:46.540784Z",
     "start_time": "2020-06-27T15:41:07.823171Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_PJ4OVdBm4s8"
   },
   "outputs": [],
   "source": [
    "# model.fit(dataset,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eYRNG57Govdc"
   },
   "outputs": [],
   "source": [
    "# model.save('machado_gen_mjr.h5') Model Trained on Google Colabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Step 6: Generating text\n",
    "\n",
    "Currently our model only expects 128 sequences at a time. We can create a new model that only expects a batch_size=1. We can create a new model with this batch size, then load our saved models weights. Then call .build() on the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T17:46:23.459753Z",
     "start_time": "2020-06-27T17:46:23.178141Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_iXG3VJvEXWM"
   },
   "outputs": [],
   "source": [
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "model.load_weights('machado_gen_mjr.h5')\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T17:46:27.274228Z",
     "start_time": "2020-06-27T17:46:27.269516Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "LAX3p7_YEilU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 64)             7488      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 117)            120159    \n",
      "=================================================================\n",
      "Total params: 3,488,823\n",
      "Trainable params: 3,488,823\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T17:46:33.276844Z",
     "start_time": "2020-06-27T17:46:33.269334Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
    "    '''\n",
    "    model: Trained Model to Generate Text\n",
    "    start_seed: Intial Seed text in string form\n",
    "    gen_size: Number of characters to generate\n",
    "\n",
    "    Basic idea behind this function is to take in some seed text, format it so\n",
    "    that it is in the correct shape for our network, then loop the sequence as\n",
    "    we keep adding our own predicted characters. Similar to our work in the RNN\n",
    "    time series problems.\n",
    "    '''\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = gen_size\n",
    "\n",
    "    # Vectorizing starting seed text\n",
    "    input_eval = [char_to_ind[s] for s in start_seed]\n",
    "\n",
    "    # Expand to match batch format shape\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty list to hold resulting generated text\n",
    "    text_generated = []\n",
    "\n",
    "    # Temperature effects randomness in our resulting text\n",
    "    # The term is derived from entropy/thermodynamics.\n",
    "    # The temperature is used to effect probability of next characters.\n",
    "    # Higher probability == lesss surprising/ more expected\n",
    "    # Lower temperature == more surprising / less expected\n",
    "\n",
    "    temperature = temp\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "\n",
    "    for i in range(num_generate):\n",
    "        # Generate Predictions\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        # Remove the batch shape dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # Use a cateogircal disitribution to select the next character\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # Pass the predicted charracter for the next input\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        # Transform back to character letter\n",
    "        text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "    return (start_seed + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T17:47:46.582606Z",
     "start_time": "2020-06-27T17:47:41.120021Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bS69SG5D5lwd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maria»0:\n",
      "\n",
      "«A moça foi bem, porque fica um tanto assim que,\n",
      "pendelo. Baptista Sophia onde vimos dahi a todos.\n",
      "\n",
      "--Os cabellos não vieram respirou constrangida no jardim de Quincha,\n",
      "fitavam a ir adeante de si, apostou-se, passea á revoctadão. Não podia\n",
      "resistrar mal e generopha. A lua, só então olhavam caminhal a differença; eram buscadas, ao vel-a noite de Humanitas. Os outros homens\n",
      "que trocassemos um defeito mesmo mal. Naturalmente, não se explicam os defeitos na tenra. Meu pae\n",
      "fará o lenço, sem nada, nem os olhos, e passeava a tempo. Tendo-lhe descobrir. Mas nem só\n",
      "os passessos, raros nunca!\n",
      "\n",
      "       *       *       *       *       *\n",
      "\n",
      "1 de Novem possumavam o interesse.\n",
      "\n",
      "Jantavam as costas do vostura, e o furor, a sou o\n",
      "iam, falando dos seus olhos. Um bom chegou ao pescoço, onde os cinco\n",
      "contos, não sei se tinha ir para si. Então os encontrou _semblem de Maio.\n",
      "\n",
      "Reverante, olhava para a Italia e da deloridade\n",
      "ás orelhas de trinta. Era uma sombra de uma secula menter, deitar-lhe o tempo da vis\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"Maria\",gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T17:58:48.410271Z",
     "start_time": "2020-06-27T17:58:43.729310Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bS69SG5D5lwd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CASMURRO III\n",
      "\n",
      "\n",
      "Pedro e Paulo viu-o; delibentei, que\n",
      "bem passam a aurora, provavelmente o que foi por\n",
      "isso. Não me lembra, bem a senhora tinha ao proprio Rubião que vae sair do\n",
      "ceitaço. Demaia,\n",
      "consolei-o a dama, que é ella que ra viste que fariam vencedor.\n",
      "Mal podia continuar. Bem o carinho acclamada estava abençoa não se\n",
      "podem nunca mais. Ouviu-aspiar ao gospo, de natureza, consultar o\n",
      "tratem, e perde--2       *       *       *  Deus a exageração do\n",
      "cosinheiro, obrigado o beiço, trocam para a filha, saiu\n",
      "obediente, ou o que quer que festejava, par de nhão, mas a lante marcava a aborrecer-se,\n",
      "agradaveis que\n",
      "isto presente, o moço secreto dos inglezes, o presente, um verdadeiro e proximo,\n",
      "quando lhe leu uma sensação peccada de Lobo Neves que queira,\n",
      "e effectivamente ajuda-me a quatro horas,\n",
      "desde o desejo de ir baixado, este é o frequentemente de figurar os que\n",
      "batiam á minha humidina e bom, como um tal caso prazer com prosa.\n",
      "Justamente o seu criado, por sedo o resto. Casa Braz Cubas_, com os ded\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\" CASMURRO \",gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T18:01:16.981348Z",
     "start_time": "2020-06-27T18:00:50.543346Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bS69SG5D5lwd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rio de Janeiro     tudo, e é uma doce recebida no seculo. Mas o\n",
      "alienista me deu dous annos. Já não trazia talvez de manhã. Como\n",
      "veiu, acharia em minha casa, de péuco tempe; conspira algumas semanas todas, um\n",
      "fino, e fazia pagar no meio do charuto, mas do laço de Lisboa e de Japhet e Senhor que lhe fiz\n",
      "um bello te podia attural-o.\n",
      "\n",
      "Um preceder não ser namorar, uma vez presa, a clausuza, que os jo\n",
      "agora constante, Flora prometteu-se aos seus ouvidos, as respostas\n",
      "largas, é certo, e eu prometti não denas saudades penos que D.\n",
      "Benedicta não tem o senhor era bonita. Eu mesmo não faça de nós; temo\n",
      "rasgado ao edio.\n",
      "\n",
      "Eram onzes. Olhavam e cabeças, e prologos de Menriso. O Humanitismo homem se não deu ficar\n",
      "e teimam nada, e, ainda cá porque...\n",
      "\n",
      "--Oh! Carmo, é objecção com Guiomar, disse Venuzindo ao essenciado\n",
      "esse curioso. Um antigo bom, creio até á experielha\n",
      "de a vestidos á não faltar-me no céu. E contei-lhe o rosto de\n",
      "mofeis, até que só instifava as arvores nem de Escobar, mas a Capitú, iamos de pé. Aos\n",
      "seus conselhos esperapannadas de sua missa, nos seus libertos. Em\n",
      "seguida, ao ver achal-beira, nem menos o senhor aos vereadores, é a mesma. Ouve-me no trabelho, viver\n",
      "o livro, e meio reias, ficavam furiosos, a palestra do Manduca! exclamou mentendo-se para o outro. O perpetua, fortuna.\n",
      "Ao espirito do desembargador possue, faz uma pessoa sua. Mas não\n",
      "póde. Custamente, repetiu o fresco, excessivo esmero. A verdade é\n",
      "dividia contando\n",
      "se tentava ao diabo, arrenegar e mais de um reuvar inteiramente\n",
      "a proposito de que se demorem eu sei o que viesse delle, iam correndo-se.\n",
      "Guiomar não vinha razanha. Ouvi com muita esesclara senhora, recuou dual do costume._\n",
      "\n",
      "13.--E as suas ultimas palavras, peores, é a antigitação com que foi\n",
      "a phrase sorrisse delle; porque não vaes, e nenhum outro.\n",
      "Contem-me? A mulher risse do homem e o lavadouro; elles sorriam, a saber\n",
      "acabou de o fazer. Desva villa, essas viagem? Talvez estas cousas pão nas\n",
      "cazas, olhos no ar, parecia menos do que triste. Nunca maijava\n",
      "a voltar para os dous, porque só agradecia, a animação do momento de roupão á conversação; phenomeno\n",
      "curioso, a proposta de algumas saudades e desfianças. _Tinta novos, e a situação é importuna;\n",
      "podia ser exercicio, mas proposito e por favida. Talvez não imagina\n",
      "como se ama, melhor que tambem pensava na mesma\n",
      "mulher, e vir a mana confusão, ter a manga i acheia\n",
      "bella cruel e insinta sem voltar aos homens, menos as suas meias, Até amanhã.\n",
      "\n",
      "Rubião replicou Ayres, á Casa Verde? Ha pessoas de criança, ria; tal\n",
      "foi a carta della acabada, a vermos,\n",
      "esticando as malas, como um espesso proposta. Vim\n",
      "de menino A belleta!_ Imagina que ja manhãs de cazada com\n",
      "a fé. Luiz Alves abria-a, como protonotario Lhobasse Tristão, nada; logo\n",
      "que elle proprio tenta, diz que as outros...\n",
      "\n",
      "--Esta palavra? Traçava de todo o medo ia a illusão, podia ser um abylhecimento.\n",
      "Conhecia a pedir-lhe este (nada é um grande prudencia, é objecto\n",
      "para elle e a morte. Ha propositos interrogados: a presidencia.\n",
      "Olhou ohio ao\n",
      "diabo. Esperou e riscou pela nebeção dessa expressão, quando a ideia de\n",
      "Carlos Maria. A mesma politica (como do carro... Inclino-me de ideias fazia\n",
      "visitas, sem toda a esmosoria do cap. XU VIITILISCIME\n",
      "\n",
      "De Rie de Janeito, commum das _Memorias, posto\n",
      "foi uma dôr visita como uma republica, fazendo corresponder logo ao gabinete, objecto do\n",
      "cesso. E apenas desviou o representante do rosto da antiga manhã\n",
      "de 1877 dura. E conta-me Não, podendo a\n",
      "andar, e Aguiar não louva muito a tracessarem com feria e caminho-a. As mulheres é uma encressão do\n",
      "enthusiasmo.\n",
      "\n",
      "--Estava amor. E se foi impossivel que elle recusou...\n",
      "_Jorge approximou-se delle? pensou Capitú.\n",
      "\n",
      "--EMa ponta: é possível?\n",
      "\n",
      "--Eu não, respondeu Japhet: por outras feições,\n",
      "que eu levaei bom conveniente da calumnia é que Luiz Alves approva de hypotodio voltou a dentro. Ouviam falhando\n",
      "inteiramente, os que era novo assim debia que nas virtudes que\n",
      "deitam commigo. Já não estavamos para a paz e fóra, e alegravam-me\n",
      "desdem do que ouvi, nem tornar a caduilha. Ao caixão dos bellos oito annos, os quinhentos metter\n",
      "isto. Eu não tendi que ha ceças tez muito tempo, levava-os\n",
      "a respeito da aventura.\n",
      "\n",
      "Comprehenda o desejo jardar estas palavras: «Anda, a indole de\n",
      "tedio, todo esses collho de hyspedido do Nicoláu, e nada mais. Então os batadas não\n",
      "sograssem as rementes paginas cabres, em todo caso a ter cinco hirandas, as\n",
      "seus gestos, sentado quando vinham sonitos, e para que se\n",
      "pudesse, senti o resto dos seus meritos e annos.\n",
      "Talvez Tristão te fosse expedido. A terrivel é comudo, nunca visto, sem falta. Não me\n",
      "pareceu coco, a esposa apparencia do habito! Não é melhor era\n",
      "a Republica, confesso que foi o menino da apontanca, e ella parecia\n",
      "entrar a estar com elles no bobse:\n",
      "\n",
      "--Tambem digo isto;\n",
      "praças commigo?\n",
      "\n",
      "Foi o major Senhor a vesava, aborrecido, no mais fundo da opinião, é\n",
      "por lhe a comprar outra vez da cabocla, pôr a tarde veiu, e\n",
      "o calor é deitar-se na cara monte a\n",
      "impassaria. Mas falando das avisos, que cae uma ciu e agitação em\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\" Rio de Janeiro  \",gen_size=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:25:15.932654Z",
     "start_time": "2020-06-28T18:24:47.026092Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bS69SG5D5lwd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A LUVA DE CASMURRO IM não foi sentar-se n'um collete,\n",
      "tão cedo estivesse á dubição, sem deitar a noite visava-lhe a\n",
      "ideia da mulher, ao vel-a preso um relevo dae passou. Só depois de a pedir lhe\n",
      "não fica que as mimosadios de Camõista.\n",
      "\n",
      "Vencer deste, quaesquer que fosse, mas apenas dizia\n",
      "quatro horas da tarde... Bonra, diante nos seus barbeiros. Quem não foi nada\n",
      "condemnariam, e, se não foi uma atternação de algarismos, sem o soube, do\n",
      "barbeiro, vá propria. Quando tem muito zemando,\n",
      "respondeu que este fugir lhe bons expos os meios de\n",
      "secretaria. Mas devo lhe\n",
      "digo uma. Passou a juro.\n",
      "\n",
      "--Venha? perguntava-as com trincada, e uma administração fizeram\n",
      "em quebro hoje ou a andar, porque não faz mal impossivel. Olhou alguns\n",
      "instantes, mas vão profundamente, e diga que Deus, na vespera.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CAPITULO LIII\n",
      "\n",
      "\n",
      "Naquella\n",
      "noite amanheceu o motivo da patria, com\n",
      "que respondente emquanto Não. Você vae Luiz Alves.\n",
      "\n",
      "--Vá lá. Se é vista alguma cousa.\n",
      "\n",
      "--Nem eu, nem em fantos, conclui por\n",
      "medico-se ou vagabular.\n",
      "\n",
      "--Jesus! éu tornava jantar.\n",
      "\n",
      "       *       *       *       *\n",
      "\n",
      "19 de Junh,\n",
      "pausado, é bonico da creança? É de tarde?\n",
      "Supponhamo-nos na memoria. Recusava só em pessoa exclamação e de\n",
      "madrinha, um esforço interno manso e desaboto. A um cancho de\n",
      "parenta, com uma ou duas horas, no fim de ver cair; o capitão\n",
      "voltaria a um dodo a V. Ex. como é que ella houvesse\n",
      "um pouco mais, nem pouco, mas pouco treferem assim, para de\n",
      "outro tempo, mas de uma vez, esperei-o aos objectos de republica. A mulher\n",
      "que ella mesma, ao que Rubião estava desappareceu empanou a convurso, a bocca finissima Justina,\n",
      "poz leval-o da expressão de algumas horas, sem\n",
      "queim descer commigo, era ella, quasi ficar calamente lento. Simão Bacamarte compluta\n",
      "o que vimos em escala, na primeira é que, se o namorara contra a sua primeira nove anno,\n",
      "mas da alma. Eras della muito obrigado ao avê estar a entrar no tacto de\n",
      "ternura, ao que o Lamba que Deus estava razão; amanhã com a praia de\n",
      "Nossa Senhona; suspirava o nariz, ouvindo.\n",
      "\n",
      "--Não tenho tres de proposito.\n",
      "\n",
      "--Ahi é delle.\n",
      "\n",
      "--Meu filho, nos não você podia havel-o em poucas semanas de felicitação.\n",
      "\n",
      "Oh! o senhor é a mesma couens de aventura. Como doce, gesto ditastico?\n",
      "\n",
      "--Crime a quella dous velhos homem.\n",
      "\n",
      "Tudo se podia havel-o mal. Nicoláu foi solta-a em um sentimento não é feliz. Qual! Um susso,\n",
      "uma José Dias passeando, e, para signal menos e\n",
      "visvo. Note-se,--«_se é que não nomeio, nem falasse, principalmente conscieitavam ao Jos Bosta dellas; e, apezar do\n",
      "gesto e enfiou, pediu-lhes o rosto claroso e recebido. Não obstante, o viuvo\n",
      "escassivo, como um restrurgo de colenderia...\n",
      "\n",
      "--Não digo que não, pigava os remedio\n",
      "aos olhos e escreveram a mesma esperança. D. Benedicta pensou que o\n",
      "rapazos aos tepios da villa, mas não é mais amigo do\n",
      "Viala. Ella pode detel-o, e lá, mandaram para\n",
      "Petropolis? Minos recommendasse os principios.» Não, não podia\n",
      "ser. Dava um tilbury que não tirava a toada um delles, mas a principio: «Se não fallava\n",
      "justamente casar o Estado. De certo teve um relogio da chacara. Da cidade\n",
      "José desde, no meio do nosso amor era uma companheira lasta, e é simples oleda. Já me suste, a pessoa veiu\n",
      "morrer, horas escurou a abalar o marido observar a cihação do\n",
      "estylo. Padua obedeceu, resguando a donoropa no primeiro doutrina, a um amigo, não\n",
      "é por a animação diversas, maneiras\n",
      "da visinhança dos seus profundos, a impassibilidade de ouvir os olhos, a\n",
      "propria ir debaixando-se ao chão.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CAPITULO CXLVIII\n",
      "\n",
      "\n",
      "Destinava das bodas de\n",
      "minha mãe. Neste fé, incompleta. O conapé ao moço no\n",
      "cerebro, sem abanar os defuntos? Teve impeto de\n",
      "ir entrar nisso, nem a presença de Barbacena. Gastava-lhe comprar um theatro,\n",
      "levadas, e iguou o homem fora; bradaram della, e é bom discreta\n",
      "e de materia prometi algum sucredar inteiramente. A razão\n",
      "é causa daquelle\n",
      "conceito. Não importa; a minha protestante está muito acto para\n",
      "arrepensar o principio do meu criador. Quando sahio e lastimoso, n'aquelle gemeo\n",
      "aos meus suspensorios, era instantanea afferente. Sahiste, comparando a toda perda de uma\n",
      "mesma alegria, ultima esperança e a mulher do brinde que me falará com\n",
      "ardor, conselhos, Ayres não lhe faça esses, nem que coubesse a ternura um dos\n",
      "filhos nos estudos, duas mesmas qualidades do\n",
      "vosso coração. Os menos concessidos! Os rapazes frouxos. Não vi\n",
      "um poubo menos depois; os olhos, por exemplo?\n",
      "\n",
      "Os mesmos no coração do major:o sujeito sem escandalos, brotarem tudo\n",
      "ao fim da parte religiosa,-tos situação, uns aos olhos de Carlos Maria, a primeira que,\n",
      "para não ser. Era tarde; vindo a mãe observasse a cumprir a mesma grande\n",
      "envelhecer, como murando, resistes a Fetra.\n",
      "\n",
      "    Naturalmente, obedecesse do primeiro ar de\n",
      "coração, soluçava a dignidade delles, e eu\n",
      "era raivesse pom doudo, ao pé da cama, a\n",
      "moça com o seu unico dezeme negativação pessoal, nem a restabelecel-os horas, e promptamente o bichiza, todos me apresentaram, trabalho expresso, carinhos, reparava os olhos\n",
      "com tano.\n",
      "Era o Guleio, vendo-se teimente com a alma; vendo-se bem que\n",
      "está nas mãos, pro\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"A LUVA DE CASMURRO \",gen_size=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:28:46.682007Z",
     "start_time": "2020-06-28T18:28:16.515940Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bS69SG5D5lwd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A LUVA DE CASMURRO DO ANESADOS DA MADOVII\n",
      "\n",
      "\n",
      "Adiava para rectar a exposição, a\n",
      "impossibilidade de commoscaça aborrece a idéa francezamente\n",
      "a filha, parava, lembrou-se, e seguiram. José Dias desculpe rapaz, e a propria\n",
      "edição propriamente ouvi outro. Talvez poí nelle um formito,\n",
      "uma filha de familia, suspirando a causa da minha cosida, depois\n",
      "toda a ausencia de Pedro. Mas eu tenão acompanharia um turbo na\n",
      "cidade e da especie, como era pilherna?\n",
      "\n",
      "Rubião, grotante, designado, a regra particular, o cerebro de\n",
      "alma que, por não saber a conversação foi cousa, mas\n",
      "é mais alegre e fecho de que todos restamente meio dinheiro, se\n",
      "puder almoçar, e vi que esta syprovanda já lá peço a da minha velha: «Anniscou taes do outro ebige,\n",
      "não menos que o dia do casamento. O protector deres de\n",
      "cabeça, respondeu-lhe que vielimento resurra a uma mesa. Não\n",
      "lhe tivesse o farto de duas janellas, vendo o titulo possivel. D. Carmo não disse a colera fosse\n",
      "critica do moço, ferindo, sentado na rua, começando ao golpe desta senhora\n",
      "cobara. Mas o olhar de Flora deixara razão, era um\n",
      "moço algum dão cousa que a este houve é que não, que\n",
      "sim:\n",
      "\n",
      "                Verdade da sociedade definitiva. Não faço\n",
      "nada de Casa Velda? Viu-a sempre lhe pareceu coco de espectaculos, etc. EAl-É\n",
      "que é o resto, pessoa novamente. Capitú respondeu\n",
      "que é boa concessão de encontrosa e gósto de inconveniencia. Não, não posso; logo; e, se ouve\n",
      "tal casacapadelhonte é a mesma unica palavra da\n",
      "minha existencia do tempo.\n",
      "\n",
      "Talvez por isso achava que a segunda differença! era, fóra para\n",
      "evitar esse emelho, que lá phenomeno se repetia, mas que\n",
      "no infinito. Tu que os sobretudo falou. Quiz excluir, que as meninas, e até\n",
      "hoje alguns noivos, ambos naturalmente, cabello episodio.\n",
      "\n",
      "Jo vistasse um traceito agnona agradecida e pela alma canindidade na\n",
      "cadeira e fechou a crista. A intenção della comprehendeu a guerra, a vida nova a via fazer-se discreto de verdade, e ainda bem?\n",
      "\n",
      "--Certamente. E fizel-a, porque simples apontador de publicidade.\n",
      "Tinha eu separadamente o marido, mandou correndo, elle fonhe\n",
      "a moça, com o seu logar da conversação, do que o busta de uns embebas-me\n",
      "eza seguida, uma com outra. Tudo insoliva lagrimas.\n",
      "E lá iamou a austeridade? «Que roça?\n",
      "\n",
      "--Não, não digo que não. Mas jantarei?\n",
      "\n",
      "--Mas...\n",
      "\n",
      "--Eu bem podia dizer-lhe ella que é um filho, Carmo é (re proposito, no\n",
      "In. não posso fazer com a presidencia, sentei-pe primeiro. Tristão voltou ainda\n",
      "melhor nesse dia, levantou o rosto como um escravo, esquecia-se\n",
      "um pouco para o espelho. Não era melhor por si o mesmo que\n",
      "nenhum, ia surdir-me. Santára mal podia ler a necessibação\n",
      "de que dava á Gamboal; lembranças, etc. Que buscasse, no dia em que\n",
      "os olhos de raiva, que por lá era seu, ou almo do silencio, e não queria prevismol o sentimento,--que\n",
      "um homem, que obrossou de todo. No\n",
      "cap. XI, pois já terá lido menos ferias, e, figurando:\n",
      "\n",
      "--Não, não és ta?\n",
      "\n",
      "--Uma das cousas eram bonzos, até cedo, a agitação viva da\n",
      "cidade, ergendelámos guardar o braço com desdem, e a noite em que\n",
      "elle sostia, deixava-se estar cainha, e acabei depronta.\n",
      "Gastou-se, foi principal do rosto; no gabinete era tal que ella derrubava os\n",
      "olhos; mas repousava estalar dalli á exclamação: «A nossa leitura ainda nascia; póde ser que fosse, não\n",
      "tes ta de repouso; estou prompto, de quem reflecti esta.\n",
      "\n",
      "--Viagem não creia.\n",
      "\n",
      "Queria muitos, se tinha secredor, de tal folhagenhendo\n",
      "que o senhor estava prestes a a contental-o. Brigar_, mas não\n",
      "póde cuidar nem casar. Não foi logar, e pedi-lh'o; é mais só murmurar a\n",
      "mesma. O advogado era Levar os seus primeiros instantes; a principio consta\n",
      "quasi riga-a familiaridades, e obedreceu-me cão estava diante do trabalho»,\n",
      "menos glaria para continuar a casa nos olhos; algumas notas ue menos a\n",
      "seguldada. Ez quanto a escrypulo que o livro foi ssem com a\n",
      "nurração de esperar á fortuna que o resto, e a namorada no modesto\n",
      "impeto de leval-o pé, e Bancluía a outra mãe. «O\n",
      "ministro_ era o respeito ás cortezias. Mas o estylo\n",
      "dessa\n",
      "moça defini iu enfidente, disseram-lhe que não estefio caminhara, e apertou\n",
      "logo. Não pude ver o Rubião, a não ser o mal; para a meza.\n",
      "\n",
      "Quando a bocca, porém, a incompleta de Carlos Maria, a todos\n",
      "trabalhos da inveja que a do Ouvidor, creio; nada, mamãe pede--os deixei\n",
      "a matar a você, que foi senhor das minhas ideias. As duas almas no\n",
      "meu sentido e da rua, frio, quasi á porta; soube sentir segurar que), escreveu\n",
      "as leis prégias, fazenda em que alguem lhe poupava as modas de um\n",
      "calculo, e, filha de um antigo, que era já uma de tudo. O essencial\n",
      "foi um sorriso triste livro. Não obstante, destanava de um\n",
      "dondecro de Escobar a dominação para a justiça, podecez levantar para\n",
      "Lisboa, nem esse? É só um projectanci outra prova a gente fóra de\n",
      "nada como fórma, um salto para elle e apprendeu por um\n",
      "moço ou desembargador. Aperfeiçoando-lhe o Quincas Borba, que ambos lh'os não tem\n",
      "consideração e de o rever, e pedia-lhe que morria tão bonita, murmurava. Marco da vascia ir com um principio de José\n",
      "Dias puçarei a resposta novelles se ama a c\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"A LUVA DE CASMURRO \",gen_size=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:32:52.922438Z",
     "start_time": "2020-06-28T18:32:24.375357Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bS69SG5D5lwd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A LUVA DE CASMURRO II\n",
      "\n",
      "\n",
      "A missa do _coupé_ e um presente e o\n",
      "governo devia cazar logo no papel, a morte do autor, e todos os seus\n",
      "considerados de alegria. Era um espirito de vinte e cinco annos, e eu não\n",
      "estou alguns passos no cerebro, como de outra cousa. Deus me disse:\n",
      "\n",
      "--Não digo que não. Se eu tivesse a intenção de um probosito. Palha acudiu a mulher, não\n",
      "havia nada. A noite vinha tambem para o seminario, tinha o aspecto\n",
      "do partido recto e de restaurar a minha mãe e\n",
      "do pae, pela primeira vez, a menor destinada a\n",
      "dispensar o chapéo, esperou que não vinhas com as suas mãos de creanças. A manhã della\n",
      "chegasse a baroneza e a maneira desta divida. Parece que é casada.\n",
      "\n",
      "--Está bom, perdoa-lhe de todos os lados, a vida de que o comprar para o meu quarto de hora,\n",
      "e contavam com o fim de a anterior, e, a parede pouco tempo a alma de pessoas que definitivamente lhe\n",
      "interessam a menos para mim. De quando em quando, esses dous annos de conversação para o fim de deixar nenhuma\n",
      "pessoa que se dispersasse; mas não falo de uma cousa nem lhe pedia com\n",
      "a mão tremula, como se ella quizesse. Eu, apertando-lhe a mão, aliás o principio do governo, a proposito disso, com a desattenção de\n",
      "Estevão, e eu começou a aborrecel-o, e a solidão podia ser melhor, e a sympathia\n",
      "colloca da mãe, e não se sabe calar o enterro no meio do lagem, o que\n",
      "iam-se apanhados no chão, e para a mulher, não tendo\n",
      "visto, nem a mesma cousa. Tinha para a mesma pessoa. Viveu as primeiras tribuna, e agora proprio lembrou-se\n",
      "de ser apreciar. Talvez não ha casar com interesse. Elles ia demonstrando no\n",
      "collegio, onde a mulher devem estar no carro, no meio do carro, a ver se\n",
      "a viu levar a morte do cazal Aguiar. Não digo que não era faria a\n",
      "caixa da viuva. Mas o tempo era tarde; a mãe delle recolheram-se\n",
      "ao grande consentido. A mim mesmo lhe pareceu que fosse, mas não foi por esse tempo que elle resume sentir o dia em que o verdadeiras\n",
      "figuras do diabo comprido, e a mãe della a mesma cousa. Cada um\n",
      "delles desceu de hoje, e assim a deixaram outro de intervallaminario, e a ingleza\n",
      "perdeu-lhe a mão. Neste ponto, não me consultasse, se não fosse o assumpto\n",
      "da villa, e adivinhava a mão do costume, e a amar na cabeça.\n",
      "\n",
      "--Visse bem, disse ella.\n",
      "\n",
      "--Mas porque não vem cá fóra. Que queria para feliz. Algumas vezes, parece que a vida não\n",
      "é raro da vida. Pedi das outras vezes. «A segunda não caza em casa, no meio do tempo, que é\n",
      "um bilhete de Virgilia, não foi por esse tempo novamente em particular. Vinha a escolher\n",
      "uma cousa mais para a porta, e tornou a declaração\n",
      "de um homem de beijos, mas não trazia ir tambem. Tinha estas palavras de ambos. A insolução\n",
      "e a segunda de uma só costumenta. Quando eu me encheu a vontade de\n",
      "ambos, e a commoção que me consultasse o convite que ia escrever uma\n",
      "palavra que havia em casa da madrinha; era um modo de fugir aos ouvidos do pae e da mãe\n",
      "foi andando. Venderam com elles o principio dos namorados.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CAPITULO XXXVIII\n",
      "\n",
      "\n",
      "Destino aggrava-os para dentro. Era\n",
      "muito feio, de certo, mas a mãe não teve achar no trecho e materia de\n",
      "conversação, e por mais promptada a folha, e o marido\n",
      "estava recente dos dous filhos por meio de camara. Se não fosse\n",
      "com dezesete annos, respondeu o ultimo desastre de mau cova, tendo lento de uma secreção\n",
      "especial do testamento. A mãe resolveu ir á fazenda e senhora, não\n",
      "digo que não podia ser irmão de _coupé_ era uma grande opera.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CAPITULO CXVIII\n",
      "\n",
      "\n",
      "Ao destino desde a proposito\n",
      "de uma pessoa. Mas eu não poderia ser de todo no segundo impeto de sair.\n",
      "\n",
      "--Mas então no fim do anno.\n",
      "\n",
      "Rita achou-a para mostrar á fundação da moça, parecia estar em\n",
      "casa da baroneza, talvez não seria mal do imperador, e a\n",
      "saudade da consciencia traz comsigo. No dia seguinte, a vida universal é insigne, não ha nada tão feliz. Conseguiu que não, que não era preciso mais nada.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CAPITULO CXVII\n",
      "\n",
      "\n",
      "Estevão de alguns serviços\n",
      "nos jornaes, e fez um para outro. Esperou contados de outro, na egreja de\n",
      "S. José, ao pé da mãe, que não sabia nada a não parecer\n",
      "que responder, quando eu lhe dizia a mesma cousa. D. Claudia pensava no dia seguinte, e na quarta\n",
      "\n",
      "\n",
      "Vá de a ver a baroneza, pela rua do Ouvidor, estava alegre, tão enthusiasmada, que estava presente, e desceu\n",
      "do Rio de Janeiro. Um caso o meu seio, receitado e cortido; mas, espere\n",
      "algum grande e de superfluo, da casa em que elle não entendassem na\n",
      "proposta. Mas você não se lembra que eu faz como se occupa devéras. Mas não; não vae; e o barbeiro foi mesmo.\n",
      "\n",
      "Tinham resolver a natureza e senhora de si. Destinaram ambos a beijar a mão, que era indispensavel com ella. Assim os\n",
      "proprios casos de uma especie de afirmação de Capitú. Estas cousas de familia, estão o\n",
      "interesse, e desceu a recolher-se para ser dado a algumas feições,\n",
      "recommendando-se com os olhos no chão, e deixando-lhe por alguns dias,\n",
      "e depois de alguns instantes, systema tinha medo. A verdade é que\n",
      "não tinha nada, porque elle não podia recuar. Prima Justina venceu a um\n",
      "canto, e fez um gesto de esperança, e a melancolia começa\n",
      "metter-se no largo do Senhor\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"A LUVA DE CASMURRO \",gen_size=5000, temp=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dff5xCHIeEHO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "00-Generating-Text-with-RNNs.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "TF-M1-24j",
   "language": "python",
   "name": "tf-m1-24j"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
